{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNVquyeUYYYir6wXypsybmf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2XRhqepbLGpu","executionInfo":{"status":"ok","timestamp":1697268690165,"user_tz":-420,"elapsed":31550,"user":{"displayName":"Thắng Nguyễn Chí","userId":"15683748687676759592"}},"outputId":"d75b219e-91be-4502-d28b-ba73bcd3b6ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers<0.15,>=0.14 (from transformers)\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n","Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.0\n","Collecting py_vncorenlp\n","  Downloading py_vncorenlp-0.1.4.tar.gz (3.9 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting pyjnius (from py_vncorenlp)\n","  Downloading pyjnius-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: py_vncorenlp\n","  Building wheel for py_vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py_vncorenlp: filename=py_vncorenlp-0.1.4-py3-none-any.whl size=4306 sha256=2a89ff132673802dc947e539de626e461c9909e1192674297857bdba5592adaf\n","  Stored in directory: /root/.cache/pip/wheels/d5/d9/bf/62632cdb007c702a0664091e92a0bb1f18a2fcecbe962d9827\n","Successfully built py_vncorenlp\n","Installing collected packages: pyjnius, py_vncorenlp\n","Successfully installed py_vncorenlp-0.1.4 pyjnius-1.6.0\n"]}],"source":["!pip install transformers\n","!pip install py_vncorenlp"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('./drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YvXbURHnjQeu","executionInfo":{"status":"ok","timestamp":1697268740528,"user_tz":-420,"elapsed":50376,"user":{"displayName":"Thắng Nguyễn Chí","userId":"15683748687676759592"}},"outputId":"6cc06517-7e37-4883-b917-2305973eb088"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at ./drive\n"]}]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import TensorDataset, DataLoader"],"metadata":{"id":"C4FBYFAvlS-O","executionInfo":{"status":"ok","timestamp":1697269305251,"user_tz":-420,"elapsed":457,"user":{"displayName":"Thắng Nguyễn Chí","userId":"15683748687676759592"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["import re\n","import py_vncorenlp\n","\n","py_vncorenlp.download_model(save_dir='./')\n","segment_model = py_vncorenlp.VnCoreNLP(annotators=[\"wseg\"], save_dir='./')"],"metadata":{"id":"ArjXu6PwP7KP","executionInfo":{"status":"ok","timestamp":1697268773578,"user_tz":-420,"elapsed":28254,"user":{"displayName":"Thắng Nguyễn Chí","userId":"15683748687676759592"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","tokenizer = AutoTokenizer.from_pretrained('/content/drive/MyDrive/DS105/model_save')\n","model = AutoModelForSequenceClassification.from_pretrained('/content/drive/MyDrive/DS105/model_save')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CSFj6RuAi_u9","executionInfo":{"status":"ok","timestamp":1697268790492,"user_tz":-420,"elapsed":16935,"user":{"displayName":"Thắng Nguyễn Chí","userId":"15683748687676759592"}},"outputId":"c59e1cc6-49ec-46be-803f-c8a68d56ffad"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["def remove_emoji(text):\n","    emoji_pattern = re.compile(\"[\"\n","        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n","        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n","        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n","        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n","        u\"\\U00002500-\\U00002BEF\"  # chinese char\n","        u\"\\U00002702-\\U000027B0\"\n","        u\"\\U00002702-\\U000027B0\"\n","        u\"\\U000024C2-\\U0001F251\"\n","        u\"\\U0001f926-\\U0001f937\"\n","        u\"\\U00010000-\\U0010ffff\"\n","        u\"\\u2640-\\u2642\"\n","        u\"\\u2600-\\u2B55\"\n","        u\"\\u200d\"\n","        u\"\\u23cf\"\n","        u\"\\u23e9\"\n","        u\"\\u231a\"\n","        u\"\\ufe0f\"  # dingbats\n","        u\"\\u3030\" \"]+\", flags=re.UNICODE)\n","    return emoji_pattern.sub(r'', text)\n","\n","def remove_special_characters(text):\n","    pattern = r\"[^\\w\\s.,;:?]\"\n","    return re.sub(pattern, \"\", text)\n","\n","def from_logit_to_label(logit):\n","  return 'Positive' if logit == 0 else 'Negative'"],"metadata":{"id":"5PfYxlZCj6_x","executionInfo":{"status":"ok","timestamp":1697270536329,"user_tz":-420,"elapsed":4,"user":{"displayName":"Thắng Nguyễn Chí","userId":"15683748687676759592"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["def classification_review(text: list, tokenizer=tokenizer, model=model):\n","  input_ids, attention_masks = [], []\n","  sentences = text.copy()\n","\n","  for i in range(len(text)):\n","    text[i] = text[i].replace('\\n', '. ')\n","    text[i] = remove_emoji(text[i])\n","    text[i] = remove_special_characters(text[i])\n","    text[i] = segment_model.word_segment(text[i])[0]\n","\n","    encoded_dict = tokenizer.encode_plus(\n","        text[i],\n","        max_length=100,\n","        padding='max_length',\n","        return_attention_mask=True,\n","        truncation=True\n","    )\n","\n","    input_ids.append(encoded_dict['input_ids'])\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","  input_ids = torch.tensor(input_ids)\n","  attention_masks = torch.tensor(attention_masks)\n","\n","  dataset = TensorDataset(input_ids, attention_masks)\n","  dataloader = DataLoader(dataset, shuffle=False, batch_size=32)\n","\n","  model.eval()\n","\n","  for batch in dataloader:\n","    b_input_ids, b_attention_mask = batch\n","\n","    with torch.no_grad():\n","      result = model(b_input_ids,\n","                     token_type_ids=None,\n","                     attention_mask=b_attention_mask)\n","\n","  logits =result.logits\n","\n","  labels_out = torch.argmax(logits, dim=1)\n","\n","  for i, sent in enumerate(sentences):\n","    print(\"{} : {}\".format(sent, from_logit_to_label(labels_out[i])))\n","\n","  return labels_out"],"metadata":{"id":"qx7sVOx8P7ox","executionInfo":{"status":"ok","timestamp":1697270538120,"user_tz":-420,"elapsed":3,"user":{"displayName":"Thắng Nguyễn Chí","userId":"15683748687676759592"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["res = classification_review(['Hàng hóa tệ'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UIKcH6f8k4dK","executionInfo":{"status":"ok","timestamp":1697270708287,"user_tz":-420,"elapsed":917,"user":{"displayName":"Thắng Nguyễn Chí","userId":"15683748687676759592"}},"outputId":"77b317b5-edfb-4d04-cec1-61cd5e82c0d6"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Hàng hóa tệ : Negative\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"CdTS4FmTNuo0"},"execution_count":null,"outputs":[]}]}